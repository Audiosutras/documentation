{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Yea its Documentation","text":""},{"location":"amazing_lists/","title":"Amazing Lists for Machine Users","text":"<p>A collection of managed lists on github and some of my own for progamming and operating system quality of life.</p>"},{"location":"amazing_lists/#github-managed-lists","title":"Github Managed Lists","text":"<p>Awesome Algorithms A curated list of awesome places to learn and/or practice algorithms</p> <p>All About RSS A list of RSS related stuff: tools, services, communities and tutorials, etc.</p> <p>Alternative Frontends Overview of alternative open source front-ends for popular internet platforms (e.g. Youtube, Twitter, etc.)</p> <p>Awesome \ud83d\ude0e Awesome lists about all kinds of interesting topics</p> <p>Awesome Actions A curated list of awesome actions to use on GitHub</p> <p>Awesome CLI Apps \ud83d\udda5 \ud83d\udcca \ud83d\udd79 \ud83d\udee0 A curated list of command line apps</p> <p>Awesome Compose These samples provide a starting point for how to integrate different services using a Compose file and to manage their deployment with Docker Compose.</p> <p>Awesome Hacking A collection of various awesome lists for hackers, pentesters and security researcher</p> <p>Awesome Icons A curate list of awesome Web Font Icons</p> <p>Awesome (Gem-Packaged) Jekyll Plugins A collection of awesome Jekyll plugins adding converters, generators, filters &amp; tags, importers, new commands &amp; switches, and more.</p> <p>Awesome Neovim Neovim is a Vim-based text editor engineered for extensibility and usability, to encourage new applications and contributions.</p> <p>Awesome Public Datasets This is a list of topic-centric public data sources in high quality. They are collected and tidied from blogs, answers, and user responses. Most of the data sets listed below are free, however, some are not. This project was incubated at OMNILab, Shanghai Jiao Tong University during Xiaming Chen's Ph.D. studies. OMNILab is now part of the BaiYuLan Open AI community.</p> <p>Awesome Python Typing Collection of awesome Python types, stubs, plugins, and tools to work with them</p> <p>Awesome Self-Hosted A list of Free Software network services and web applications which can be hosted on your own servers</p> <p>Awesome Sysadmin A curated list of amazingly awesome open-source sysadmin resources.</p> <p>Awesome Zsh Plugins A collection of ZSH frameworks, plugins, themes and tutorials.</p> <p>Free Media Heck Yeah (FMHY) The largest collection of free stuff on the internet</p> <p>Open Source MacOS Apps \ud83d\ude80 Awesome list of open source applications for macOS.</p> <p>The Book of Secret Knowledge A collection of inspiring lists, manuals, cheatsheets, blogs, hacks, one-liners, cli/web tools and more.</p>"},{"location":"amazing_lists/#self-managed-list","title":"Self-managed List","text":""},{"location":"amazing_lists/#blockchain","title":"Blockchain","text":"<p>Solidity A statically-typed curly-braces programming language designed for developing smart contracts that run on Ethereum.</p>"},{"location":"amazing_lists/#cheatsheets","title":"Cheatsheets","text":"<p>Nano Editor</p> <p>TMux - <code>man tmux</code></p> <p>Vim - <code>:help</code></p>"},{"location":"amazing_lists/#command-line","title":"Command Line","text":"<p>tmux-resurrect persists tmux environment across system restarts.</p>"},{"location":"amazing_lists/#discord","title":"Discord","text":"<p>Discord Developer Portal</p> <p>Discord Me Discover your next favorite hangout with Discord Me, where finding fun and engaging Discord servers is a breeze. It's a treasure hunt for communities that share your interests, from gaming to art, all easily accessible. Dive into a world of discovery, make new friends, and join conversations that light up your day!</p> <p>Discord.py discord.py is a modern, easy to use, feature-rich, and async ready API wrapper for Discord.</p> <p>PyCord A fork of <code>discord.py</code></p>"},{"location":"amazing_lists/#e-book-readers","title":"E-book Readers","text":"<p>Librum-Reader A modern and opensource ebook reading solution</p> <p>Bookworm A simple ebook reader for Elementary OS</p> <p>Foliate - Source Code Modern e-book reader of the quality of Librum-Reader except without cloud syncing and the need for an account.</p>"},{"location":"amazing_lists/#frontend-general","title":"Frontend (General)","text":"<p>Electron Build cross-platform desktop apps with Javascript, HTML, and CSS. See <code>Flatpak</code> for distributing the application on Linux.</p> <p>Tanstack Query Powerful asynchronous state management for TS/JS, React, Solid, Vue and Svelte</p> <p>DataTables Add advanced interaction controls to your HTML tables the free &amp; easy way</p> <p>TailwindCSS Rapidly build modern websites without ever leaving your HTML.</p> <p>Sass Lang Sass is the most mature, stable, and powerful professional grade CSS extension language in the world.</p> <p>Styled Components CSS for the <code>&lt;Component&gt;</code> Age</p> <p>HTMX htmx is a library that allows you to access modern browser features directly from HTML, rather than using javascript.</p> <p>Alpine JS Your new, lightweight, JavaScript framework.</p> <p>PNpM Fast, disk space efficient package manager</p>"},{"location":"amazing_lists/#gitlab","title":"Gitlab","text":"<ul> <li>Self Hosting Docs</li> </ul>"},{"location":"amazing_lists/#google","title":"Google","text":"<p>Clasp - Command Line Apps Script Projects</p> <p>Setting up your OAuth consent screen You must configure an OAuth consent screen before using an OAuth 2.0 client ID. This article describes OAuth consent screen settings and their impact on how your Google Cloud Platform project requests OAuth scopes from a Google Account.</p>"},{"location":"amazing_lists/#linux-development","title":"Linux Development","text":"<p>Flatpak Learn to build and distribute Linux native desktop applications using Flatpak.</p>"},{"location":"amazing_lists/#linux-distributions","title":"Linux Distributions","text":"<p>Linux Mint</p>"},{"location":"amazing_lists/#lora-radio-communications","title":"LORA Radio Communications","text":"<p>Meshtastic is open source, off-grid, decentralized, mesh network built to run on affordable, low-power devices. - Source Code - Documentation - Discord Server</p> <p>Reticulum is the cryptography-based networking stack for building local and wide-area networks with readily available hardware. Reticulum can continue to operate even in adverse conditions with very high latency and extremely low bandwidth. The vision of Reticulum is to allow anyone to operate their own sovereign communication networks, and to make it cheap and easy to cover vast areas with a myriad of independent, interconnectable and autonomous networks. Reticulum is Unstoppable Networks for The People. - Source Code - Documentation - Matrix Channel</p>"},{"location":"amazing_lists/#matrix","title":"Matrix","text":"<p>Website Here An open network for secure, decentralized communcation</p> <p>Github Organization</p>"},{"location":"amazing_lists/#pentesting-tools","title":"Pentesting tools","text":"<p>Flipper Zero is a portable multi-tool for pentesters and geeks in a toy-like body. It loves hacking digital stuff, such as radio protocols, access control systems, hardware, and more. It's fully open-source and customizable, so you can extend it in whatever way you like. - Docs - Forums - Discord</p> <p>Hak5 is industry leading hacker tools &amp; award winning hacking shows for red teams, pentesters, cyber security students and IT professionals.</p> <p>Kali Linux is a Linux distribution designed for digital forensics and penetration testing.</p>"},{"location":"amazing_lists/#php","title":"PHP","text":"<p>Download Here</p> <p>Laravel The PhP Framework for Web Artisans</p> <p>Composer A Dependency Manager for PHP</p>"},{"location":"amazing_lists/#pine64","title":"Pine64","text":"<p>Pine 64 is a community-driven company focused on creating high-quality, low-cost ARM devices and, more recently, RISC-V devices for individuals and businesses around the globe. Wiki / Docs</p>"},{"location":"amazing_lists/#python","title":"Python","text":"<p>Download Here</p> <p>Pallets Projects</p> <ul> <li>Click: Python composable command line interface toolkit</li> <li>Flask: The Python micro framework for building web applications.</li> <li>Jinja: A very fast and expressive template engine.</li> </ul> <p>Django The Web framework for perfectionists with deadlines.</p> <p>Django Rest Framework Web APIs for Django. \ud83c\udfb8</p> <p>Quickstart: Compose and Django This quick-start guide demonstrates how to use Docker Compose to set up and run a simple Django/PostgreSQL app.</p> <p>Wagtail The powerful Python CMS for modern websites</p> <p>Celery Celery is a simple, flexible, and reliable distributed system to process vast amounts of messages, while providing operations with the tools required to maintain such a system.</p> <p>Requests Requests is an elegant and simple HTTP library for Python, built for human beings.</p> <p>Mongoengine is a Document-Object Mapper for working with MongoDB from Python</p> <p>Motor Asynchronous Python driver for MongoDB</p> <p>Poetry Python packaging and dependency management made easy</p> <p>PIPX Install and Run Python Applications in Isolated Environments</p> <p>Asyncpg is a database interface library designed specifically for PostgreSQL and Python/asyncio.</p> <p>Psycopg 3 Psycopg 3 is a modern implementation of a PostgreSQL adapter for Python.</p> <p>PyMongo is a Python distribution containing tools for working with MongoDB (Synchronous)</p> <p>Python Dotenv Python-dotenv reads key-value pairs from a <code>.env</code> file and can set them as environment variables. It helps in the development of applications</p> <p>Python Social Auth Python Social Authentication Made Simple</p> <p>IP Info Accurate IP address data that keeps pace with secure, specific, and forward-looking use cases.</p>"},{"location":"amazing_lists/#qortal","title":"Qortal","text":"<p>The Qortal Network, Truly Decentralized, Community-Driven and Developed, Completely Custom Built, and Truly Decentralized. With its Unique Egalitarian Consensus Protocol, Leveling System, and Blockchain-Secured Distributed Data Network, QORTAL is Designed To Create A Completely Secure and Liberating Digital World. - Development Portal - Wiki - Documentation - Discord Server</p>"},{"location":"amazing_lists/#react","title":"React","text":"<p>React Hooks Introduced in version 16+, React Hooks are designed to be a functional approach to build react applications.</p> <p>React Charts Beautiful, flexible, highly-performant charts for React</p> <p>Redux A Predictable State Container for JS Apps</p> <p>Next.js App Router The React Framework for the Web. Links to docs for Next.js projects using app router rather than page router</p>"},{"location":"amazing_lists/#security","title":"Security","text":"<p>ZaProxy The Zed Attack Proxy (ZAP) is one of the world\u2019s most popular free security tools and is actively maintained by a dedicated international team of volunteers. It can help you automatically find security vulnerabilities in your web applications while you are developing and testing your applications. It's also a great tool for experienced pentesters to use for manual security testing.</p> <p>ZAP Action Full Scan A GitHub Action for running the ZAP Full Scan to perform Dynamic Application Security Testing (DAST).</p> <p>The ZAP full scan action runs the ZAP spider against the specified target (by default with no time limit) followed by an optional ajax spider scan and then a full active scan before reporting the results. The alerts will be maintained as a GitHub issue in the corresponding repository.</p> <p>WARNING this action will perform attacks on the target website. You should only scan targets that you have permission to test. You should also check with your hosting company and any other services such as CDNs that may be affected before running this action. ZAP will also submit forms which could result in a large number of messages via, for example, 'Contact us' or 'comment' forms.</p>"},{"location":"amazing_lists/#self-hosting","title":"Self-Hosting","text":"<p>Movie Web - Movie-web is a web app for watching movies easily. This service works by displaying video files from third-party providers inside an intuitive and aesthetic user interface. (Active Instances) (Self Hosting Docs) (Providers Docs) <code>MIT</code> <code>Docker/Typescript</code></p> <p>Anna's Archive - A web app that hosts a search engine for books, science papers, comics, magazines, and more. (Demo) <code>Creative Commons Zero v1.0 Universal</code> <code>Docker/Python</code></p>"},{"location":"amazing_lists/#single-board-computers","title":"Single Board Computers","text":"<p>Raspberry Pi, designers of single-board and modular computers, built on the Arm architecture, and running the Linux operating system - Documentation</p>"},{"location":"amazing_lists/#vue","title":"Vue","text":"<p>Vue API Reference</p> <p>Pinia The intuitive store for Vue.js</p> <p>Nuxt.js</p>"},{"location":"content_management/contentful_draft_mode/","title":"Enabling Draft Previews for Contentful Development &amp; Staging Environments","text":"<p>This article is a tutorial for enabling Contentful Delivery API draft previews so that developers, quality assurance, and stakeholders can review and edit content drafts and extend features without changes interrupting content published on the production site.</p>"},{"location":"content_management/contentful_draft_mode/#files","title":"Files","text":""},{"location":"content_management/contentful_draft_mode/#add-contentful_params-to-your-constantsts-file","title":"Add <code>CONTENTFUL_PARAMS</code> to your <code>constants.ts</code> file","text":"<pre><code>/* constants.ts */\nexport const CONTENTFUL_PARAMS: {\n  host?: string | undefined;\n  space: string | undefined;\n  accessToken: string | undefined;\n} = {\n  // host defaults to cdn.contentful.com\n  host:\n    process.env.CONTENTFUL_DRAFT_MODE == \"true\"\n      ? \"preview.contentful.com\"\n      : undefined,\n  space: process.env.CONTENTFUL_SPACE_ID,\n  accessToken:\n    process.env.CONTENTFUL_DRAFT_MODE == \"true\"\n      ? process.env.CONTENTFUL_PREVIEW_ACCESS_TOKEN\n      : process.env.CONTENTFUL_ACCESS_TOKEN,\n};\n</code></pre>"},{"location":"content_management/contentful_draft_mode/#import-contentful_params-and-export-contentfulclient-from-apits-file","title":"Import <code>CONTENTFUL_PARAMS</code> and export <code>contentfulClient</code> from <code>api.ts</code> file","text":"<pre><code>/* api.ts */\nconst contentful = require(\"contentful\");\n/* assumption:  constants.ts is a sibling in the same directory as api.ts */\nimport { CONTENTFUL_PARAMS } from \"./constants\";\n\nexport const contentfulClient: any = contentful.createClient(CONTENTFUL_PARAMS);\n</code></pre>"},{"location":"content_management/contentful_draft_mode/#add-contentful-secrets-as-environment-variables-for-your-various-environments","title":"Add contentful <code>secrets</code> as <code>environment variables</code> for your various environments","text":"<pre><code># Exclude CONTENTFUL_DRAFT_MODE or set to false for an\n# environment that drafts should not be displayed for\n# such as production\nCONTENTFUL_DRAFT_MODE = 'true'\nCONTENTFUL_SPACE_ID = :space_id\nCONTENTFUL_PREVIEW_ACCESS_TOKEN = :preview_access_token\nCONTENTFUL_ACCESS_TOKEN = :access_token\n</code></pre>"},{"location":"content_management/contentful_draft_mode/#generating-access-tokens","title":"Generating Access Tokens","text":"<p><code>CONTENTFUL_PREVIEW_ACCESS_TOKEN</code> and <code>CONTENTFUL_ACCESS_TOKEN</code> can be generated from the <code>+ Add API key</code> button in <code>Settings</code> -&gt; <code>API Keys</code> on the contentful site. Make sure to also copy the <code>Space ID</code> for <code>CONTENTFUL_SPACE_ID</code>.</p>"},{"location":"content_management/contentful_draft_mode/#usage","title":"Usage","text":"<p>Import <code>contentfulClient</code> where you would like to use the contentful client inline with the javascript api. For example</p>"},{"location":"encryption/usb/","title":"USB Drive Encryption","text":""},{"location":"encryption/usb/#install-cryptsetup","title":"Install <code>cryptsetup</code>","text":""},{"location":"encryption/usb/#installation-on-ubuntu-and-debian-based-distributions","title":"Installation on ubuntu and debian based distributions","text":"<pre><code>sudo apt install cryptsetup\n</code></pre>"},{"location":"encryption/usb/#installation-on-arch-based-distributions","title":"Installation on arch based distributions","text":"<pre><code>sudo pacman -S cryptsetup\n</code></pre>"},{"location":"encryption/usb/#partition-usb-drive","title":"Partition USB Drive","text":""},{"location":"encryption/usb/#open-a-root-shell","title":"Open a root shell","text":"<pre><code>sudo su\n</code></pre>"},{"location":"encryption/usb/#create-2-partitions-using-fdisk","title":"Create 2 partitions using fdisk","text":"<p>[!IMPORTANT] The first partition should be unencrypted and have a rather small volume size compared to the second encrypted volume.</p> <pre><code># find the device, typically /dev/sdX where X is unknown. See size of the device to correlate\nfdisk /dev/sdX\n</code></pre> <p>Within Interactive mode</p> <pre><code># use d to delete all partitions if there any already on the device\nCommand (m for help): n # new parition\n[Press &lt;ENTER&gt; twice]\n# 5GB size for unencrypted volume\nLast sector, +/-sectors or +/-size{K,M,G,T,P} (2048-31703005, default 31703005): +5GB\n\n# create 2nd parition with remaining space on device\nCommand (m for help): n\n[Press &lt;ENTER&gt; three times]\n\nCommand (m for help): w\n</code></pre>"},{"location":"encryption/usb/#format-the-partitions","title":"Format the partitions","text":"<pre><code>mkfs.ext4 /dev/sdX1\nmkfs.ext4 /dev/sdX2\n</code></pre>"},{"location":"encryption/usb/#protect-against-pattern-based-encryption-attacks-using-dd","title":"Protect against pattern based encryption attacks using <code>dd</code>","text":"<pre><code>dd if=/dev/urandom of=/dev/sdX2 status=progress\n</code></pre>"},{"location":"encryption/usb/#encrypt-the-2nd-partition","title":"Encrypt the 2nd Partition","text":"<p>[!IMPORTANT] You need provide a passphrase to decrypt the partition after running this command</p> <pre><code>cryptsetup luksFormat \\\n--type luks2 --cipher aes-xts-plain64 --hash sha256 --iter-time 2000 \\\n--key-size 256 --pbkdf argon2id --use-urandom --verify-passphrase /dev/sdX2\n</code></pre>"},{"location":"encryption/usb/#post-encryption-commands","title":"Post Encryption Commands","text":""},{"location":"encryption/usb/#opening-the-encrypted-partition","title":"Opening the encrypted partition","text":"<pre><code>cryptsetup open /dev/sdX2 device_mapper_name\n</code></pre> <p>The partition is now mapped to <code>/dev/mapper/&lt;device_mapper_name&gt;</code></p> <pre><code>mkfs.ext4 /dev/mapper/&lt;device_mapper_name&gt;\n</code></pre> <p>The device partition can now be mounted like another partition.</p>"},{"location":"encryption/usb/#closing-the-encrypted-partition","title":"Closing the encrypted partition","text":"<p>unmount the partition like any other partition using the device mapped name and then close the connection.</p> <pre><code># assuming root shell access. use sudo otherwise\numount /dev/mapper/&lt;device_mapper_name&gt;\ncryptsetup lcose device_mapper_name\n</code></pre>"},{"location":"encryption/usb/#resources","title":"Resources","text":"<ul> <li>Linux Config Tutorial</li> <li>Arch Wiki Device Encryption Guide</li> </ul>"},{"location":"git/code_versioning_and_rollbacks/","title":"Code Versioning &amp; Rolling Back Main Branch To A Prior State","text":""},{"location":"git/code_versioning_and_rollbacks/#code-versioning","title":"Code Versioning","text":"<p>From the command line type:</p> <pre><code># make sure you are on the main branch of your project\n$ git tag\nv0.1.2\nv0.1.3\nv0.1.4\n# incrementing up, other git tags\n# ...\n</code></pre> <p>The command above lists out the git <code>tags</code> associated with the git repository. Each <code>tag</code> represents a snapshot of the codebase at a given point in time. This is both important and useful for us as developers because when something goes wrong we can use a <code>tag</code> to restore the codebase to a state when our application logic was in a good working condition.</p> <p>To create a new tag for the production branch of our application run the following:</p> <pre><code>git checkout main\ngit tag vX.X.X # where X.X.X is a version number\n</code></pre> <p>Make sure our version number is incrementally higher than the preceding <code>tags</code>. For this example, <code>v0.1.4</code> is our latest tag so our new tag will be <code>v0.1.5</code> (or <code>0.2.0</code>, its up to you).</p> <p>Now lets create our new tag <code>v0.1.5</code> and push it to the repository:</p> <pre><code>git tag v0.1.5\ngit push origin v0.1.5\n</code></pre> <p>Our tag is now associated with the remote repository. To learn more about git tags see here</p>"},{"location":"git/code_versioning_and_rollbacks/#rolling-back-main-branch-to-a-prior-state","title":"Rolling Back Main Branch To A Prior State","text":"<p>If you are reading this section then you know you messed up somewhere. We do not know yet where and we want to fix the state of our codebase. No worries, let's roll back our codebase to a prior tag.</p> <p>Sticking with the example from Codebase Versioning say we want to roll our codebase back to tag <code>v0.1.4</code> from an unknown amount of commits past <code>v0.1.5</code> because we know for certain that <code>v0.1.4</code> is a point in time when our codebase was in good health. We can run the following:</p> <pre><code>git checkout v0.1.4\ngit diff main &gt; ~/diff.patch\ngit checkout main\ncat ~/diff.patch | git apply\ngit commit -m \"Roll back to v0.1.4\"\ngit push origin main\n</code></pre> <p>This will roll back the <code>main</code> branch to <code>v0.1.4</code> while keeping commit history intact.</p>"},{"location":"github_actions/docker_cd_github_action/","title":"Github Action to Deploy Dockerfile to Remote Registry","text":"<p>Name the following file <code>docker_&lt;remote_registry_name&gt;_pkg.yaml</code> and add it to the <code>workflows</code> directory in your <code>.github</code> directory.</p> <p>This file is currently configured to build and deploy an image to github packages. Since we are running our deployment as a Github Action we also benefit with having the github package that is created from the action associated with the repository that is running the action.</p> <p>If you would like to change the remote registry update the domain value specified at <code>env.REGISTRY</code>. If you would like to update how this action is triggered update the <code>on</code> value.</p> <p>Currently this action is triggered from a github release.</p> <pre><code># .github/workflows/docker_docker_github_pkg.yaml\nname: Create and publish a Docker image\n\n# Configures this workflow to run every time a release is created.\non:\n  release:\n    types: [\"published\"]\n\n# Defines two custom environment variables for the workflow. These are used for the Container registry domain, and a name for the Docker image that this workflow builds.\nenv:\n  REGISTRY: ghcr.io\n  IMAGE_NAME: ${%raw%}{{ github.repository }}{%endraw%}\n\n# There is a single job in this workflow. It's configured to run on the latest available version of Ubuntu.\njobs:\n  build-and-push-image:\n    runs-on: ubuntu-latest\n    # Sets the permissions granted to the `GITHUB_TOKEN` for the actions in this job.\n    permissions:\n      contents: read\n      packages: write\n      #\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v4\n      # Uses the `docker/login-action` action to log in to the Container registry registry using the account and password that will publish the packages. Once published, the packages are scoped to the account defined here.\n      - name: Log in to the Container registry\n        uses: docker/login-action@65b78e6e13532edd9afa3aa52ac7964289d1a9c1\n        with:\n          registry: ${%raw%}{{ env.REGISTRY }}{%endraw%}\n          username: ${%raw%}{{ github.actor }}{%endraw%}\n          password: ${%raw%}{{ secrets.GITHUB_TOKEN }}{%endraw%}\n      # This step uses [docker/metadata-action](https://github.com/docker/metadata-action#about) to extract tags and labels that will be applied to the specified image. The `id` \"meta\" allows the output of this step to be referenced in a subsequent step. The `images` value provides the base name for the tags and labels.\n      - name: Extract metadata (tags, labels) for Docker\n        id: meta\n        uses: docker/metadata-action@9ec57ed1fcdbf14dcef7dfbe97b2010124a938b7\n        with:\n          images: ${%raw%}{{ env.REGISTRY }}{%endraw%}/${%raw%}{{ env.IMAGE_NAME }}{%endraw%}\n          tags: |\n            type=semver,pattern={%raw%}{{version}}{%endraw%} # use git tag\n      # This step uses the `docker/build-push-action` action to build the image, based on your repository's `Dockerfile`. If the build succeeds, it pushes the image to GitHub Packages.\n      # It uses the `context` parameter to define the build's context as the set of files located in the specified path. For more information, see \"[Usage](https://github.com/docker/build-push-action#usage)\" in the README of the `docker/build-push-action` repository.\n      # It uses the `tags` and `labels` parameters to tag and label the image with the output from the \"meta\" step.\n      - name: Build and push Docker image\n        uses: docker/build-push-action@f2a1d5e99d037542a71f64918e516c093c6f3fc4\n        with:\n          context: .\n          push: true\n          tags: ${%raw%}{{ steps.meta.outputs.tags }}{%endraw%}\n          labels: ${%raw%}{{ steps.meta.outputs.labels }}{%endraw%}\n</code></pre> <p>Accompanying documentation to added to a project's readMe.md</p> <pre><code>This project utilizes [Github Actions](https://docs.github.com/en/packages/managing-github-packages-using-github-actions-workflows/publishing-and-installing-a-package-with-github-actions#publishing-a-package-using-an-action) for deploying a production ready docker container to the github container registry. For more information see [working with the container registry](https://docs.github.com/en/packages/working-with-a-github-packages-registry/working-with-the-container-registry).\n\nTo push a new container image to github packages create a `release` from the `main` branch with a specified [git tag](https://git-scm.com/book/en/v2/Git-Basics-Tagging). The git tag should be labelled with a version number such as [1.2.3](https://github.com/docker/metadata-action?tab=readme-ov-file#tags-input).\n</code></pre>"},{"location":"github_actions/poetry_ci/","title":"Python - Poetry CI Github Action","text":"<p>The below instructions assume that you are already using poetry and have <code>pyproject.toml</code>.</p> <pre><code># ./github/workflows/ci.yml\nname: CI\n\non:\n  push:\n    # On merge into master\n    branches:\n      - master # or main\n  # On pull requests\n  pull_request:\n  # manually trigger workflow\n  workflow_dispatch:\n\njobs:\n  run_test_suite:\n    name: Run Test Suite, Style Guide, &amp; Code Checks\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Checkout Repository\n        uses: actions/checkout@v4\n\n      - name: Setup Python 3.12\n        uses: actions/setup-python@v4\n        with:\n          python-version: 3.12\n\n      - name: Install Pipx &amp; Poetry\n        run: |\n          python3 -m pip install --user pipx\n          python3 -m pipx ensurepath\n          pipx install poetry\n\n      - name: Install Dependencies &amp; Test Dependencies\n        run: poetry install --no-interaction --only=main,dev,tests\n\n      - name: Style Guide Check &amp; Code Check\n        run: poetry run pre-commit run -a\n\n      - name: Run Pytest &amp; Code Coverage\n        run: poetry run pytest --cov-config=.coveragerc --cov=. tests/\n</code></pre> <ul> <li>Assumes pytest and precommit has been installed by poetry</li> </ul> <pre><code>-&gt; poetry add pytest pytest-mock pytest-cov --group tests\n-&gt; poetry add pre-commit --group dev\n</code></pre> <p>Starter <code>.pre-commit-config.yaml</code> file. Place in root directory of project</p> <pre><code>repos:\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v4.5.0\n    hooks:\n      - id: check-yaml\n      - id: check-docstring-first\n      - id: end-of-file-fixer\n      - id: trailing-whitespace\n  - repo: https://github.com/psf/black\n    rev: 24.3.0\n    hooks:\n      - id: black\n  - repo: https://github.com/pycqa/isort\n    rev: 5.13.2\n    hooks:\n      - id: isort\n  - repo: https://github.com/python-poetry/poetry\n    rev: 1.8.2 # add poetry version here\n    hooks:\n      - id: poetry-check\n      - id: poetry-lock\n      - id: poetry-install\n</code></pre> <p>Starter <code>.coveragerc</code> file. Place in root directory of project</p> <pre><code>[run]\nomit = tests/*\n\n[report]\nfail_under = 90\n</code></pre> <p>After adding these files locally initialize pre-commit and push to remote repo</p> <pre><code>-&gt; pre-commit install\n-&gt; pre-commit run -a\n# git commit and push to repo\n</code></pre>"},{"location":"github_actions/pypi_releases/","title":"Github Actions for Releasing Python Packages to PYPI","text":"<p>Add <code>pre-release.yml</code> to <code>.github/workflows</code>. This workflow is triggered on tag creation and publishes to <code>tests.pypi</code>:</p> <pre><code>name: Publish to Test.PyPI\non:\n  push:\n    # when a new tag has been pushed to repo\n    tags:\n      - \"*.*.*\"\n\njobs:\n  package_pre_release:\n    name: Publish Package to Test PyPI\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Checkout Repository\n        uses: actions/checkout@v4\n\n      - name: Setup Python 3.11\n        uses: actions/setup-python@v4\n        with:\n          python-version: 3.11\n\n      - name: Install Pipx &amp; Poetry\n        run: |\n          python3 -m pip install --user pipx\n          python3 -m pipx ensurepath\n          pipx install poetry\n\n      - name: Configure Test.PYPI as source to publish to\n        run: |\n          poetry config repositories.testpypi https://test.pypi.org/legacy/\n          poetry config pypi-token.testpypi -&gt;{%raw%}{{ secrets.TEST_PYPI_PASSWORD }}{%endraw%}\n\n      - name: Publish package\n        run: poetry publish --build -r testpypi\n</code></pre> <ul> <li>Github Secret Used: <code>TEST_PYPI_PASSWORD</code>- API token generated on test.pypi.org</li> </ul> <p>Add <code>release.yml</code> to <code>.github/workflows</code>. Triggered on Github Releases and publishes to <code>pypi</code>:</p> <pre><code>name: Publish to PyPI\non:\n  release:\n    types: [published]\n\njobs:\n  package_release:\n    name: Publish Package to PyPI\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Checkout Repository\n        uses: actions/checkout@v4\n\n      - name: Setup Python 3.11\n        uses: actions/setup-python@v4\n        with:\n          python-version: 3.11\n\n      - name: Install Pipx &amp; Poetry\n        run: |\n          python3 -m pip install --user pipx\n          python3 -m pipx ensurepath\n          pipx install poetry\n      - name: Configure PYPI as source to publish to\n        run: |\n          poetry config pypi-token.pypi -&gt;{%raw%}{{ secrets.PYPI_PASSWORD }}{%endraw%}\n\n      - name: Publish package\n        run: poetry publish --build\n</code></pre> <ul> <li>Github Secret Used: <code>PYPI_PASSWORD</code> - API token generated on pypi.org</li> </ul> <p>Update repo's <code>ReadMe.md</code> with procedure for running a deployment:</p> <pre><code>1. In `pyproject.toml` *bump* the version number `*.*.*`\n\n2. Create a [git tag](https://git-scm.com/book/en/v2/Git-Basics-Tagging) with the new version number `*.*.*` you specified in `pyproject.toml`.\n\n3. Push the newly created tag `git push origin *.*.*` to the repository. This will trigger the `pre-release.yml` github workflow to publish our package to `test.pypi`. The pre-release can be seen [here](https://test.pypi.org/project/getdat/) for testing. Install with:\n\n```bash\n-&gt; python3.11 -m pip install --index-url https://test.pypi.org/simple/ &lt;pyproject package name&gt; --extra-index-url https://pypi.org/simple &lt;tool.poetry.dependencies except python&gt;\n```\n- *Note*: `--extra-index-url` option is pulling dependencies from `pypi.org` and not `test.pypi.org` though our package is coming in from `test.pypi.org`. Make sure to add all dependencies from `[tool.poetry.dependencies]` in `pyproject.toml` (except python) before running this command.\n\n4. *Create* a [release](https://www.toolsqa.com/git/github-releases/) on github. Make sure to select `Tags` from the toggle menu. Select the latest tag (highest version number). Name the release `v*.*.*`. Make sure the version number in `pyproject.toml` syncs up with the release version. *Click* `Publish release`. This will kick off our `release.yml` workflow to publish our package to `pypi`. The release can be seen [here and installed](https://pypi.org/project/getdat/) for production use. Install with:\n\n```bash\n-&gt; pipx install &lt;pyproject package name&gt;\n```\n</code></pre>"},{"location":"github_actions/python_poetry_docker/","title":"Python Poetry Docker Examples","text":""},{"location":"github_actions/python_poetry_docker/#production","title":"Production","text":"<p>Example <code>Dockerfile</code></p> <pre><code>FROM python:3.13-alpine\n\nARG POETRY_VERSION=1.8.4\n\nENV PYTHONFAULTHANDLER=1\nENV PYTHONUNBUFFERED=1\nENV PYTHONHASHSEED=random\nENV PIP_NO_CACHE_DIR=off\nENV PIP_DISABLE_PIP_VERSION_CHECK=on\nENV PIP_DEFAULT_TIMEOUT=100\n\n# System deps:\nRUN apk add gcc musl-dev &amp;&amp; \\\npip install \"poetry==$POETRY_VERSION\"\n\n# Copy only requirements to cache them in docker layer\nWORKDIR /code\nCOPY poetry.lock pyproject.toml /code/\n\n# No need to create a virtualenv for this isolated environment:\nRUN poetry config virtualenvs.create false\n\n# Creating folders, and files for a project:\nCOPY . /code\n</code></pre> <p>See Github Action to Deploy Dockerfile to Remote Registry. Once the production Dockerfile is in place, upon a github release a new image will be created and added to the remote repository.</p> <p>Example <code>compose.yaml</code> file.</p> <pre><code>services:\n  bot:\n    # since this is production pull the latest image from ghcr.io or another remote registry\n    image: ghcr.io/&lt;username&gt;/&lt;repo_name&gt;:latest\n    # Here install the dependency groups that are need from pyproject.toml\n    # Typically only the \"main\" dependencies in production\n    command: sh -c \"poetry install --no-interaction --only=main &amp;&amp; &lt;start command for project&gt;\"\n    restart: always\n    environment: # see .env_file if you rather specify a file instead of env vars individually\n      # Add environment variables here\n      - MONGODB_URI=mongodb://root:&lt;MONGO_INITDB_ROOT_PASSWORD&gt;@mongo:27017/\n    depends_on:\n      - mongo\n  # example of including a database service\n  mongo:\n    image: mongo\n    restart: always\n    environment:\n      - MONGO_INITDB_ROOT_USERNAME=root\n      - MONGO_INITDB_ROOT_PASSWORD=&lt;password&gt;\n    volumes:\n      - mongodata:/data/db\nvolumes:\n  mongodata:\n</code></pre> <p>Within your production environment you will run the following to stand up your docker container.</p> <pre><code>docker compose up -d\n</code></pre>"},{"location":"github_actions/python_poetry_docker/#development","title":"Development","text":"<p>Example <code>Dockerfile-dev</code></p> <pre><code>FROM python:3.13-alpine\n\nARG POETRY_VERSION=1.8.4\n\nENV PYTHONFAULTHANDLER=1\nENV PYTHONUNBUFFERED=1\nENV PYTHONHASHSEED=random\nENV PIP_NO_CACHE_DIR=off\nENV PIP_DISABLE_PIP_VERSION_CHECK=on\nENV PIP_DEFAULT_TIMEOUT=100\n\n# System deps:\nRUN apk add gcc musl-dev &amp;&amp; \\\npip install \"poetry==$POETRY_VERSION\"\n\n# Copy only requirements to cache them in docker layer\nWORKDIR /code\nCOPY poetry.lock pyproject.toml /code/\n\n# No need to create a virtualenv for this isolated environment:\nRUN poetry config virtualenvs.create false\n\n# Run as a non-privileged user\nRUN addgroup -S code &amp;&amp; adduser -S -G code code --home /home/code --shell /bin/bash\nRUN chown -R code:code /code\nRUN chmod 755 /code\nUSER code\n\n# Copy source files into application directory\nCOPY --chown=code:code . /code\n</code></pre> <p>Example docker compose file. This file could be <code>compose.yaml</code> and your production compose file could be <code>compose-prod.yaml</code> or some variation of this to distinguish between the files. Its up to you.</p> <pre><code>services:\n  bot:\n    build:\n      context: .\n      dockerfile: Dockerfile-dev\n    develop:\n      ### provides hot reloading\n      watch:\n        - action: sync+restart\n          # paths are relative to compose file\n          path: ./&lt;python app&gt;\n          target: /code/&lt;python app&gt;\n        - action: rebuild\n          path: pyproject.toml\n    # Note: tests dependencies are included alongside main dependencies.\n    command: sh -c \"poetry install --no-interaction --only=main,tests &amp;&amp; &lt;start command for project&gt;\"\n    restart: always\n    environment:\n      - MONGODB_URI=mongodb://root:&lt;MONGO_INITDB_ROOT_PASSWORD&gt;@mongo:27017/\n    depends_on:\n      - mongo\n  # example db service. In this case mongodb\n  mongo:\n    image: mongo\n    restart: always\n    environment:\n      - MONGO_INITDB_ROOT_USERNAME=root\n      - MONGO_INITDB_ROOT_PASSWORD=&lt;password&gt;\n    volumes:\n      - mongodata:/data/db\nvolumes:\n  mongodata:\n</code></pre> <p>Run the project locally with <code>docker compose watch</code> to utilize hot reloading.</p>"},{"location":"github_actions/zap-full-scan/","title":"Perform Weekly Security Audits with ZAProxy &amp; Github Actions","text":"<p>Below is <code>security.yml</code>. Path: <code>.github/workflows/security.yml</code>. Make sure to replace <code>&lt;target&gt;</code> with the url for the website you are security testing:</p> <pre><code>name: Perform Weekly Security Audit with ZAProxy\n# Use ZAP Proxy to perform a full scan of the production site.\n# Scan automatically opens an issue after completion\n# with results of the audit.\n\non:\n  schedule:\n    # 00:00 UTC Midnight on Mondays\n    - cron: \"0 0 * * 1\"\n\n  # manually trigger workflow\n  workflow_dispatch:\n\njobs:\n  zap_scan:\n    runs-on: ubuntu-latest\n    name: Scan Production Site\n    steps:\n      - name: Set Date (NOW) as Variable\n        id: set-now\n        run: |\n          echo \"NOW=-&gt;(date +'%Y-%m-%d')\" &gt;&gt; \"-&gt;GITHUB_OUTPUT\"\n\n      - name: Checkout Repo for .zap/rules.tsv\n        uses: actions/checkout@v4\n        with:\n          ref: main\n\n      - name: ZAP Full Scan\n        # https://github.com/zaproxy/action-full-scan\n        uses: zaproxy/action-full-scan@v0.7.0\n        with:\n          target: \"&lt;target&gt;\"\n          rules_file_name: \".zap/rules.tsv\"\n          issue_title: \"Security Report - -&gt;{%raw%}{{ steps.set-now.outputs.NOW }}{%endraw%}\"\n          artifact_name: \"zap_scan_-&gt;{%raw%}{{ steps.set-now.outputs.NOW }}{%endraw%}\"\n</code></pre> <p>Below is an example <code>rules.tsv</code>. Path: <code>&lt;root_dir&gt;/.zap/rules.tsv</code>. If using VSCode make sure to disable using spaces for tabs when editing this file. Github automatically generates a table for <code>.tsv</code> and <code>.csv</code> files. You'll know VS Code inserted spaces instead of tabs if this file does not render as a table in the Github UI</p> <pre><code>10020 IGNORE (Missing Anti-clickjacking Header)\n10021 IGNORE (X-Content-Type-Options Header Missing)\n10035 IGNORE (Strict-Transport-Security Header Not Set)\n10038 IGNORE (Content Security Policy (CSP) Header Not Set)\n10063 IGNORE (Permissions Policy Header Not Set)\n10096 IGNORE (Timestamp Disclosure - Unix)\n10098 IGNORE (Cross-Domain Misconfiguration)\n40040 IGNORE (CORS Misconfiguration)\n</code></pre>"},{"location":"google_appscript/gs_classes/","title":"Useful Classes for Google AppScript","text":"<p>Below are classes that are useful for interacting with Google Workspace API using Google's Appscript language that's based on javascript</p>"},{"location":"google_appscript/gs_classes/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Emails</li> </ul>"},{"location":"google_appscript/gs_classes/#emails","title":"Emails","text":"<pre><code>class Email {\n  /* Email \n\n  Basic Email class \n  */\n  constructor(\n    emailAddresses, // comma separated list of email addresses (string)\n    attachments,\n  ) {\n    this._emailAddresses = emailAddresses;\n    this._attachments = attachments;\n    this._subject = \"Subject Not Set\";\n    this._htmlBodyArray = [];\n  }\n\n  get _htmlBody() {\n    /* Joins the html content of the email.\n\n    If not set a generic message to contact administration\n    is set.\n    */\n    if (this._htmlBodyArray.length &gt; 0) {\n      return this._htmlBodyArray.join(\" \");\n    } else {\n      return \"&lt;p&gt;Message not implemented. Contact admin.&lt;/p&gt;\";\n    }\n  }\n\n  sendEmail() {\n    /* Sends an Email */\n    const email_log = `\n      Subject: ${this._subject}\n      Body: ${this._htmlBody}\n    `;\n    console.log(email_log);\n    MailApp.sendEmail(this._emailAddresses, this._subject, this._htmlBody, {\n      htmlBody: this._htmlBody,\n      attachments: this._attachments,\n    });\n  }\n}\n</code></pre> <p>This class is meant to be inherited. For example:</p> <pre><code>class ChildEmailClass extends Email {\n  constructor(emailAddresses, attachments) {\n    super(emailAddresses, attachments);\n    this._subject = `\n      Specify a custom Subject line\n    `;\n    this._htmlBodyArray = [\n      `&lt;h1 align=\"center\"&gt;Specify the HTML of the Email Body&lt;/h1&gt;`,\n      `&lt;h3 align=\"center\"&gt;Please see the attachment below for more information.&lt;/h3&gt;`,\n      `&lt;p align=\"center\"&gt;This is great&lt;/p&gt;`,\n    ];\n  }\n}\n</code></pre> <p>In use:</p> <pre><code>const emailAddresses = `${emailAddress1},${emailAddress2}`; // as many as needed to be specified\nconst email = new ChildEmailClass(\n  emailAddresses,\n  [file], // as many as need to be specified. See File objects in API\n);\nemail.sendEmail();\n</code></pre>"},{"location":"google_appscript/gs_classes/#references","title":"References","text":"<ul> <li>MailApp</li> <li>File</li> </ul>"},{"location":"linux_mint/linux_mint_audio_issues/","title":"[Solution] Linux Mint Audio Issues","text":"<p>Answer original provided in Linux Mint 21.3 Release Notes</p> <pre><code>sudo apt install pavucontrol\n</code></pre> <p>Taken from the documentation.</p> <pre><code>This will add \"PulseAudio Volume Control\" to your menu. This application has more configuration options than the default volume control.\n</code></pre>"},{"location":"linux_mint/linux_mint_nvidia_black_screen/","title":"[Solution] Linux Mint Black Screen After Login Using Nvidia Drivers","text":"<p>Answer original provided by generix</p> <p>Edit /etc/initramfs-tools/modules:</p> <pre><code>sudo nano /etc/initramfs-tools/modules\n</code></pre> <p>Add the following non-commented lines to the end of the file:</p> <pre><code># Inside /etc/initramfs-tools/modules\n----\n----\nnvidia\nnvidia-modeset\nnvidia-drm\n</code></pre> <p><code>CTRL+X</code> then <code>Y</code> then <code>Enter</code> to exit.</p> <p>Make changes take affect:</p> <pre><code>sudo update-initramfs -u\n</code></pre> <p>Restart machine</p>"},{"location":"self_host/pihole/","title":"Pi-hole &amp; Unbound Setup Using Docker Compose","text":""},{"location":"self_host/pihole/#article-sections","title":"Article Sections","text":"<ul> <li>Background</li> <li>DNS Resolver CheatSheet</li> <li>Download The Latest Release</li> <li>Prerequiste Installation</li> <li>Docker &amp; Docker Compose</li> <li>Direnv</li> <li>Running PiHole &amp; Unbound (Linux / Mac OS)</li> <li>Linux Additional Steps</li> <li>More Useful Resources &amp; Articles</li> <li>Resources</li> <li>Articles</li> </ul>"},{"location":"self_host/pihole/#background","title":"Background","text":"<p>Pi-hole is a DNS sinkhole that is effective at blocking ads and malware by closing connections to blacklisted domains before a client can connect to them. Unbound is a validating, recursive, caching DNS resolver that increases the privacy of its users.</p> <p>This project provisions two docker containers on a user's chosen machine that always run unless stopped; one for Pihole and the other Unbound. When PiHole is configured to use Unbound as its only upstream DNS server it cuts Google, Cloudflare, and other DNS providers out from having a record of the domains you have requested. In simple terms, this means the sites you have visited. However note that your Internet Service Provider will still be able to access your DNS history without any obfuscation. For more information I found this reddit thread helpful.</p> <p>The benefits of running pi-hole and unbound in docker containers are many. To speak to a few, it is the ability to run this software across operating system (linux, mac, windows) and across computing devices. You can benefit from adblocking and malware protection on your devices at home by running pihole on a raspberry pi attached to your home network. You can also have this benefit on your machine when connected to an external network like hotel or airport wifi.</p> <p>Let's get started.</p>"},{"location":"self_host/pihole/#dns-resolver-cheatsheet","title":"DNS Resolver CheatSheet","text":"<p>The table below documents the port and internal IP address of the custom dns resolvers that this instance of Pihole comes pre-configured with.</p> DNS Resolver Internal IP Address Unbound 10.1.1.3#53"},{"location":"self_host/pihole/#download-the-latest-release","title":"Download The Latest Release","text":"<ul> <li>Download the latest release (Currently <code>v1.0.3</code>)</li> </ul> <pre><code>-&gt; wget https://github.com/Audiosutras/pihole-dockercompose/archive/refs/tags/v1.0.3.tar.gz\n-&gt; tar -xvf v1.0.3.tar.gz\n-&gt; rm v1.0.3.tar.gz &amp;&amp; cd pihole-dockercompose-1.0.3\n</code></pre>"},{"location":"self_host/pihole/#prerequiste-installation","title":"Prerequiste Installation","text":""},{"location":"self_host/pihole/#docker-docker-compose","title":"Docker &amp; Docker Compose","text":"<p>This project depends on having Docker and Docker Compose installed on the machine you plan to run Pihole on. Ensure your machine has at least 4GB of RAM.</p> <p>To check if <code>docker</code> and <code>docker-compose</code> is already installed run the following commands from the command line:</p> <pre><code>-&gt; docker --version\nDocker version 24.0.6, build ed223bc\n-&gt; docker-compose --version\ndocker-compose version 1.28.0, build d02a7b1a\n</code></pre> <p>If nothing was returned when running the above commands follow docker's recommended installation method found here under Scenario one: Install Docker Desktop for your operating system and/or linux distribution. If your machine is a Raspberry Pi or another single board computer check out these operating systems for getting docker up and running</p> <ul> <li>Casa OS</li> <li>Hypriot OS</li> </ul>"},{"location":"self_host/pihole/#direnv","title":"Direnv","text":"<p>You can export the environment variables we'll discuss but direnv is a great utility to use to have the environment variables automatically exported for you when this project is in your working directory.</p> <p>For ubuntu-based systems:</p> <pre><code>apt install direnv\n</code></pre> <p>Via homebrew:</p> <pre><code>brew install direnv\n</code></pre> <p>You may need to re-open your terminal shell here. Now let's configure our shell.</p> <p>For bash:</p> <pre><code>echo 'eval \"$(direnv hook bash)\"' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n</code></pre> <p>For zsh:</p> <pre><code>echo 'eval \"$(direnv hook zsh)\"' &gt;&gt; ~/.zshrc\nsource ~/.zshrc\n</code></pre>"},{"location":"self_host/pihole/#running-pihole-unbound-linuxmac-os","title":"Running PiHole &amp; Unbound (Linux/Mac OS)","text":"<ul> <li> <p>Download the latest release</p> </li> <li> <p>Create an <code>.envrc</code> file in the same directory as the <code>docker-compose.yml</code> file</p> </li> </ul> <pre><code>-&gt; ls\ndocker-compose.yml  READMe.md\n-&gt; touch .envrc &amp;&amp; vim .envrc # opens vim editor\n</code></pre> <p>Copy &amp; Paste the code block below into the <code>vim editor</code>.</p> <ul> <li>Replace <code>&lt;super secret password for logging into pihole dashboard&gt;</code> with your password.</li> <li>Replace <code>&lt;timezone&gt;</code> with your timezone. For example <code>America/New_York</code></li> <li>Replace <code>&lt;dns addresses&gt;</code> with the upstream dns you would like to use. If you would like to use <code>Unbound</code> write <code>'10.1.1.3#53'</code> or if you would like to use <code>Cloudflare</code> and <code>Quad 9</code> write <code>'1.1.1.1;9.9.9.9'</code> for example. There are more options available in the pihole admin than this. This just selects the default upstream providers that will be checked in the admin on system start.</li> </ul> <pre><code>export PIHOLE_PWD=&lt;super secret password for logging into pihole dashboard&gt;\n# Switch With your local TimeZone, ex: export PIHOLE_TZ=America/New_York\nexport PIHOLE_TZ=&lt;timezone&gt;\nexport PIHOLE_DNS=&lt;dns addresses&gt;\n</code></pre> <p><code>:wq</code> then <code>ENTER</code> to exit the vim editor.</p> <p>Now allow <code>direnv</code> to automatically export environment variables by running:</p> <pre><code>direnv allow .\n</code></pre> <p>Each time changes are made to the <code>.envrc</code> file this command will need to be run.</p> <ol> <li>Run the project detached as a background process.</li> </ol> <p>If you are running this project on Ubuntu (and maybe Fedora) there are additional steps that need to be completed before continuing with step 2.</p> <pre><code>-&gt; docker-compose up -d\n</code></pre> <p>Pihole and Unbound will restart automatically unless explicitly stopped by the user.</p> <p>If you are running this project on a raspberry pi or a device using the arm64 architecture and you plan on using unbound, you will need to modify the <code>unbound.image</code> value in the <code>docker-compose.yml</code> file. Change <code>mvance/unbound:latest</code> to <code>mvance/unbound-rpi:latest</code>. Save the file and then run <code>docker-compose up -d</code>.</p> <ol> <li> <p>Get the IP Address of the Pihole instance</p> </li> <li> <p>If wanting to use Pihole on the machine you just installed it on without local      network coverage, the IP address you will use for your DNS server is <code>127.0.0.1</code> (localhost).</p> </li> <li>For local network coverage, you will need to know the local IP address for the machine you placed Pihole on. Get that on linux by running</li> </ol> <pre><code>    # make sure to write down the first entry in this list\n-&gt; hostname -I\n</code></pre> <p>Note: The machine you placed pihole on would benefit from having a static IP address</p> <ol> <li> <p>Confirm PiHole is the selected upstream DNS servers selected in Step 1</p> </li> <li> <p>Navigate to <code>http://&lt;ip-address&gt;/admin</code> replacing <code>&lt;ip-address&gt;</code> with the address you obtained in step 3. If <code>127.0.0.1</code> append the port as so: <code>http://127.0.0.1:8080/admin</code></p> </li> <li>Input the <code>PIHOLE_PWD</code> password you chose in step 1 to access the admin</li> <li>Navigate to <code>Settings</code>, click on the <code>DNS</code> tab. Under <code>Upstream DNS</code> <code>Custom 1 (IPv4)</code> you should see checked <code>10.1.1.3#53</code>. This is <code>Unbound</code>'s internal IP address.</li> <li>You can uncheck this and use any of the other upstream dns servers like <code>Cloudflare</code> and <code>Quad9</code> whenever you want to.</li> <li> <p>Note Unbound being checked is contigent upon what upsteam dns providers you selected for <code>PIHOLE_DNS</code> in Step 1. If you chose <code>\"1.1.1.1;9.9.9.9\"</code> you will see <code>Cloudflare</code> and <code>Quad 9</code> checked.</p> </li> <li> <p>Start using Pihole - Article: Configure Clients to use Pihole</p> </li> <li> <p>On the Pihole installed machine you can navigate to Wifi or Network Settings and update the <code>DNS</code> section for your internet connection by inputing <code>127.0.0.1</code> as the value for this section.</p> </li> <li>For local network coverage of all devices you will need to update Static DNS settings found in your router's admin page. You will set      the DNS value to the local IP address you retrieved in step 3.</li> </ol> <p>For more Information see the article linked above for step 5.</p>"},{"location":"self_host/pihole/#linux-additional-steps","title":"Linux Additional Steps","text":"<p>In order to proceed you will need to update <code>systemd-resolved</code> or disable it.</p> <ul> <li> <p>Offical Pihole Solution for Ubuntu &amp; Fedora - Update It</p> </li> <li> <p>The Unoffical Solution for the Streets - Disable It.</p> </li> </ul> <p>Here are the steps for the official solution</p> <pre><code>-&gt; sudo sed -r -i.orig 's/#?DNSStubListener=yes/DNSStubListener=no/g' /etc/systemd/resolved.conf\n-&gt; sudo sh -c 'rm /etc/resolv.conf &amp;&amp; ln -s /run/systemd/resolve/resolv.conf'\n-&gt; sudo systemctl restart systemd-resolved\n</code></pre> <p>Here are the steps for the unofficial solution</p> <pre><code>    # The Unoffical Solution for the Streets\n-&gt; sudo systemctl disable systemd-resolved\n-&gt; sudo systemctl stop systemd-resolved\n-&gt; sudo nano /etc/NetworkManager/NetworkManager.conf\n</code></pre> <p>Add <code>dns=default</code> under <code>[main]</code> section in <code>/etc/NetworkManager/NetworkManager.conf</code></p> <pre><code># inside '/etc/NetworkManager/NetworkManager.conf'\n[main]\n...\n...\ndns=default\n...\n</code></pre> <p><code>:wq</code> then <code>ENTER</code> to exit the vim editor.</p> <p>Delete the sysmlink <code>/etc/resolv.conf</code></p> <pre><code>-&gt; rm /etc/resolv.conf\n</code></pre> <p>Restart NetworkManager</p> <pre><code>-&gt; sudo systemctl restart NetworkManager\n</code></pre> <p>Now we can proceed back to step 2 in Running PiHole &amp; Unbound.</p>"},{"location":"self_host/pihole/#more-useful-resources-articles","title":"More Useful Resources &amp; Articles","text":""},{"location":"self_host/pihole/#resources","title":"Resources","text":"<ul> <li>Pi-hole website</li> <li>Setup Pihole Docker (Official)</li> <li>Unbound as an Upstream DNS</li> </ul>"},{"location":"self_host/pihole/#articles","title":"Articles","text":"<ul> <li>PiHole Docker - Pi My Life UP</li> <li>Run PI Hole In Localhost And Some Extras - Medium</li> <li>How To Install Unbound and Pi-hole in Docker using Docker Compose</li> </ul>"},{"location":"text_editors/neovim-setup/","title":"Neovim IDE Setup","text":"<p>Neovim is a hyper-extensible Vim-based text editor. Through additional configuration provided by plugins and a window manager like tmux we can create a powerful Integrated Development Environment (IDE) comparable to VS Codium.</p>"},{"location":"text_editors/neovim-setup/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Alacritty</li> <li>Neovim</li> <li>Tmux</li> <li>Patched Fonts</li> <li>Recommended Additional Packages</li> </ul>"},{"location":"text_editors/neovim-setup/#alacritty","title":"Alacritty","text":"<p>To get the most out of neovim and tmux you will want to use a terminal that can utilizes your graphics card. I recommend using alacritty a cross-paltform, OpenGL terminal emulator.</p>"},{"location":"text_editors/neovim-setup/#neovim","title":"Neovim","text":""},{"location":"text_editors/neovim-setup/#installation","title":"Installation","text":"<p>Installation methods for your particular operating system can be found here.</p> <p>For Debian</p> <pre><code>sudo apt-get install neovim python3-neovim\n</code></pre> <p>For Ubuntu</p> <pre><code>sudo apt install neovim python3-neovim\n</code></pre> <p>For Fedora</p> <pre><code>sudo dnf install -y neovim python3-neovim\n</code></pre> <p>For Arch Linux</p> <pre><code>sudo pacman -S neovim\n</code></pre>"},{"location":"text_editors/neovim-setup/#configuration","title":"Configuration","text":"<p>I recommend installing LazyVim as your package manager. Installation is completed by cloning the repository from github.</p> <p>Backup existing plugins if you are just switching to LazyVim</p> <pre><code># required\n$ mv ~/.config/nvim{,.bak}\n\n# optional but recommended\n$ mv ~/.local/share/nvim{,.bak}\n$ mv ~/.local/state/nvim{,.bak}\n$ mv ~/.cache/nvim{,.bak}\n</code></pre> <p>Clone the starter or copy my config</p> <p>starter if you would like to configure lazy.vim yourself and follow the docs</p> <pre><code>git clone https://github.com/LazyVim/starter ~/.config/nvim\n</code></pre> <p>Use my config</p> <pre><code>git clone https://github.com/Audiosutras/nvim.git ~/.config/nvim\n</code></pre> <p>Remove the <code>.git</code> folder, so you can add it to your own repo later</p> <pre><code>rm -rf ~/.config/nvim/.git\n</code></pre> <p>Start Neovim</p> <pre><code>nvim\n</code></pre> <p>You can enable/disable plugins with <code>:LazyExtras</code> and using <code>x</code> to select plugins from the menu. Press <code>:q</code> to exit. Make sure to familiarize yourself with standard vim commands using <code>:help</code>. You learn more about plugins in use by seeing what plugins are enabling and navigating to there git repositories.</p>"},{"location":"text_editors/neovim-setup/#tmux","title":"Tmux","text":"<p>tmux is a terminal multiplexer. It lets you switch easily between several programs in one terminal, detach them (they keep running in the background) and reattach them to a different terminal.</p>"},{"location":"text_editors/neovim-setup/#patched-fonts","title":"Patched Fonts","text":"<p>In order for icons to shows up with the nvim editor 9 out of 10 times you will need a patched font. These are fonts that include the icons that are often times missing from other sources. You can download a patched font of your choice over at Nerd Fonts.</p> <ul> <li>Create or ensure <code>~/.local/share/fonts</code> directory exists on your file system</li> <li> <p>Copy the link address for the font you want to download from the <code>Download</code> button and the Command</p> </li> <li> <p>My Patched Fonts Repo</p> </li> </ul> <pre><code>wget https://github.com/ryanoasis/nerd-fonts/releases/download/v3.1.1/AurulentSansMono.zip ~/.local/share/fonts/\n</code></pre> <ul> <li> <p><code>unzip</code> the file and check the file extension. The file extension could end in <code>otf</code> or <code>ttf</code>. Create a directory within fonts that matches the file extension(s). Move the unzipped files into the corresponding file extension directory within the fonts directory.</p> </li> <li> <p>Update alacritty to use the patched. Sticking with our example.</p> </li> </ul> <pre><code>$ nvim ~/.config/alacritty/alacritty.toml\n# Add the following to the config file\n[font]\nnormal = { family = \"AurulentSansMNerdFontMono\", style = \"Regular\" }\nsize = 10.25\n</code></pre> <ul> <li>alacritty config docs</li> <li>my alacritty configuration</li> </ul>"},{"location":"text_editors/neovim-setup/#recommended-additional-packages","title":"Recommended Additional Packages","text":"<ul> <li>ripgrep This package is required by <code>telescope.nvim</code> to use the <code>live_grep</code> feature</li> <li>lazydocker A simple terminal UI for both docker and docker-compose. Make sure to read this for configuring <code>docker compose</code></li> </ul>"},{"location":"unix/extract_tar_files/","title":"Extracting Tar.gz Files","text":"<p><code>.tar.gz</code> files are a more space-efficient alternatives to compress files than <code>.zip</code> files. Github gives the option when a github release is created to download either a <code>zip</code> file or a <code>.tar.gz</code> file. For space-efficency I typically opt to download a <code>.tar.gz</code> file.</p>"},{"location":"unix/extract_tar_files/#to-extract-files-from-a-targz-file-to-current-the-working-directory","title":"To Extract files from a <code>.tar.gz</code> file to current the working directory","text":"<pre><code>tar -xvf filename.tar.gz\n</code></pre> <p>For other use cases check out this article.</p> <p>You can also run <code>man tar</code></p>"},{"location":"unix/rar_files/","title":"Extracting Rar files","text":"<p>original article</p> <p>Install <code>unrar</code>:</p> <p>Ubuntu/Linux Mint</p> <pre><code>sudo apt update &amp; sudo apt install unrar -y\n</code></pre> <p>Extract and preserve directories</p> <pre><code>unrar x filename.rar\n</code></pre> <p>Extract wihtout preserving directories</p> <pre><code>unrar e filename.rar\n</code></pre>"}]}